{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets get the csv file and write it out into train and test directories\n",
    "import urllib\n",
    "import os\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import shutil\n",
    "data_dir = \"./data\"\n",
    "def download_data(urls, label, data_dir=\"data\", train_split=80, cleanstart=False):\n",
    "    if cleanstart:\n",
    "        #dangerous!!! use with caution\n",
    "        shutil.rmtree(data_dir)\n",
    "    if not os.path.exists(data_dir + \"/train/{}\".format(label)):\n",
    "        os.makedirs(data_dir + \"/train/{}\".format(label))\n",
    "    if not os.path.exists(data_dir + \"/test/{}\".format(label)):    \n",
    "        os.makedirs(data_dir + \"/test/{}\".format(label))\n",
    "    # lets fix the seed so subsequent shuffles overwrite each other\n",
    "    # Else you have a risk of mixing train and test data and subsequent\n",
    "    # euphoria that eventually gets rekt.\n",
    "    numpy.random.seed(0)\n",
    "    np_arr = np.asarray(urls)\n",
    "    np.random.shuffle(np_arr)\n",
    "    train, test = np_arr[:train_split], np_arr[train_split:]\n",
    "    def write_data(urls, label, data_dir):\n",
    "        for url in urls:\n",
    "            #import pdb; pdb.set_trace()\n",
    "            try:\n",
    "                img_pth = data_dir + \"/{}/\".format(label) + hashlib.sha1(url).hexdigest() + \".\" + url.split(\".\")[-1]\n",
    "                if not os.path.exists(img_pth):\n",
    "                    urllib.urlretrieve(url, img_pth)\n",
    "            except Exception as e:\n",
    "                print url, e\n",
    "                \n",
    "    write_data(train, \"train/{}\".format(label), data_dir)\n",
    "    write_data(test, \"test/{}\".format(label), data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://images.jet.com/md5/44a90bfb356c7c3a0a6f0fcaa4083bb8 [Errno 2] No such file or directory: 'data/train/non_offensive/bad0cdaa50174e4758439e59ab89f16cfcc7b6bf.com/md5/44a90bfb356c7c3a0a6f0fcaa4083bb8'\n"
     ]
    }
   ],
   "source": [
    "download_data([x.rstrip() for x in open(\"offensive_urls.txt\")], label=\"offensive\")\n",
    "download_data([x.rstrip() for x in open(\"non_offensive_urls.txt\")], label=\"non_offensive\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
